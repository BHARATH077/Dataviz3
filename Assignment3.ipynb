{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from networkx.readwrite import json_graph\n",
        "import networkx as nx\n",
        "import json\n",
        "\n",
        "# Load Author Network Data\n",
        "df = pd.read_csv(\"/content/data_scopus.csv\").fillna(0)\n",
        "G = nx.Graph()\n",
        "\n",
        "def get_author_country(authors_with_affiliations):\n",
        "    first_affiliation = authors_with_affiliations.split(';')[0].strip()\n",
        "    return first_affiliation.split(',')[-1].strip()\n",
        "\n",
        "# Iterate through the DataFrame rows to create nodes and edges\n",
        "for _, row in df.iterrows():\n",
        "    authors = row['Authors'].split(',')\n",
        "    author_Id = row['Author(s) ID'].split(';')\n",
        "    Title = row['Title']\n",
        "    Year = row['Year']\n",
        "    Citations = row['Cited by']\n",
        "    Publisher = row['Publisher']\n",
        "    Authorwa = row['Authors with affiliations']\n",
        "\n",
        "    for author, author_id in zip(authors, author_Id):\n",
        "        if author_id:\n",
        "            nodes = {\n",
        "                'id': author_id,\n",
        "                'Authors': ';'.join(authors),\n",
        "                'Title': Title,\n",
        "                'Year': Year,\n",
        "                'Citations': Citations,\n",
        "                'Publisher': Publisher,\n",
        "                'Author with affiliations': Authorwa\n",
        "            }\n",
        "            G.add_node(author_id, **nodes)\n",
        "\n",
        "# Create edges based on co-authorship relationships\n",
        "for _, row in df.iterrows():\n",
        "    authors = row['Author(s) ID'].split(';')\n",
        "    for i in range(len(authors)):\n",
        "        for j in range(i + 1, len(authors)):\n",
        "            if authors[i] and authors[j]:\n",
        "                G.add_edge(authors[i], authors[j])\n",
        "\n",
        "# Generate clusters based on authors' countries\n",
        "clusters = list(nx.connected_components(G))\n",
        "\n",
        "# Assign classes to each cluster\n",
        "class_mapping = {node: idx for idx, cluster in enumerate(clusters) for node in cluster}\n",
        "nx.set_node_attributes(G, class_mapping, 'class')\n",
        "\n",
        "# Save the data as a JSON file\n",
        "coauthorship_data = {\n",
        "    'nodes': [{'id': node, **G.nodes[node]} for node in G.nodes()],\n",
        "    'links': [{'source': source, 'target': target} for source, target in G.edges()]\n",
        "}\n",
        "\n",
        "with open('coauthorship_data.json', 'w', encoding='utf-8') as outfile:\n",
        "    json.dump(coauthorship_data, outfile, ensure_ascii=False)\n"
      ],
      "metadata": {
        "id": "25kc_ocq_YYw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the publication network data as JSON\n",
        "publication_network_data = json_graph.node_link_data(G)\n",
        "\n",
        "with open('publication_network.json', 'w') as f:\n",
        "    json.dump(publication_network_data, f)"
      ],
      "metadata": {
        "id": "Mex1vhNIQ1up"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bJyi4bO4Rgpo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}